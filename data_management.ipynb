{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d258cd6e",
   "metadata": {},
   "source": [
    "# Data Management \n",
    "\n",
    "Real datasets are messy, not ordered like MNIST.\n",
    "\n",
    "**Case Study: Oxford Flowers Dataset**\n",
    "\n",
    "We have a folder full of flower images named like image_00001.jpg. The labels are stored in a .mat file\n",
    "\n",
    "**Problems in Data Preparation:**\n",
    "* Access Problems\n",
    "* Quality Problems\n",
    "* Efficiency Problems\n",
    "\n",
    "#### Data Pipelines\n",
    "\n",
    "`Data Ingestion -> Data Prep -> Modeling -> Training -> Evaluation -> Deployment`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c6c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbe3b7",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd38f60",
   "metadata": {},
   "source": [
    "### PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecf6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordFlowersDataset(Dataset):\n",
    "\n",
    "    #Setup where to find images and labels\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "\n",
    "        # lazy loading\n",
    "\n",
    "    # How many total samples\n",
    "    def __len__(self):\n",
    "        # return total number of samples\n",
    "\n",
    "    # How to get image and label number 'idx'ArithmeticError\n",
    "    def __getitem__(self,idx):\n",
    "        # load data and get label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8109a4",
   "metadata": {},
   "source": [
    "### Transformation Pipeline\n",
    "\n",
    "* Quality Problems \n",
    "* Need to handle resizing, format conversion and normalization\n",
    "\n",
    "* All images need to be of the same size in order for pytorch to stack them into  a batch.\n",
    "\n",
    "* Batches need to follow the format: [batch_size, channels, height, width]\n",
    "\n",
    "* Image can be of different sizes and formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing image sizes\n",
    "\n",
    "# resize the shorted edge to 256, then crop a square from the center\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "])\n",
    "\n",
    "# convert PIL image to tensor\n",
    "\n",
    "img_tensor = transforms.ToTensor()(img) # This also scales the pixel values from 0 to 1, and stores values in 3 channels\n",
    "\n",
    "# normalization to mean 0 and stddev 1 spreads the values evenly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bbd66e",
   "metadata": {},
   "source": [
    "Always debug and see image transformations to ensure everything works properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf898afa",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "1. split dataset to train, val, test\n",
    "2. use DataLoader to batch and serve that data efficiently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# split into train/val/test\n",
    "\n",
    "train_size = int(0.7*len(dataset))\n",
    "val_size = int(0.15*len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Create DataLoaders for each set\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c722aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to go through all the data, one batch at a time\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    ...\n",
    "\n",
    "# Get just first batch to inspect. Quick debugging\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training data\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# for val and test data, shuffling is not necessary\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98197bc6",
   "metadata": {},
   "source": [
    "## Bugproof Pipelines\n",
    "\n",
    "To make the pipeline more reliable before training \n",
    "\n",
    "1. Data Augmentation - for better generalization\n",
    "\n",
    "On the fly augmentation during training\n",
    "\n",
    "2. Corrupted Images - instead of crashing, keep log of errors and skip to the next image\n",
    "\n",
    "3. Overly aggressive augmentation - augmentation should be reasonable\n",
    "\n",
    "4. Data Tracking - which images get loaded, how often each one is accessed, how long each load takes\n",
    "\n",
    "Common Tracking errors:\n",
    "\n",
    "* Shuffling bugs\n",
    "* Performance issues\n",
    "* Data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8318e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the fly augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decddf8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
